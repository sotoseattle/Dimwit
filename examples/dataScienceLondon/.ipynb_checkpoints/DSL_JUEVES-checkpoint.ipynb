{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd '~/Dropbox/fjs6/Journal/ideolog/Dimwit/examples/dataScienceLondon/data/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/fjs6/Dropbox/fjs6/Journal/ideolog/Dimwit/examples/dataScienceLondon/data\n"
       ]
      }
     ],
     "prompt_number": 205
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from pandas import *\n",
      "import pandas\n",
      "import math\n",
      "import random\n",
      "from sklearn import preprocessing\n",
      "from sklearn import svm\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.decomposition import RandomizedPCA\n",
      "\n",
      "import sys\n",
      "sys.path.append('/Users/fjs6/Dropbox/fjs6/Journal/ideolog/Dimwit')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 206
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr_data = read_csv('train.csv', header=None)\n",
      "test_data = read_csv('test.csv', header=None)\n",
      "data = concat([tr_data, test_data], ignore_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 207
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gt_data = read_csv('trainLabels.csv', header=None)\n",
      "gt_data =np.vstack([gt_data, np.ones((data.shape[0]-gt_data.shape[0],1))*-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 209,
       "text": [
        "(10000, 40)"
       ]
      }
     ],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def heatmap(grid, C_range, g_range):\n",
      "    print(\"The best classifier is: \", grid.best_estimator_)\n",
      "    print 'best score', grid.best_score_\n",
      "    score_dict = grid.grid_scores_\n",
      "    scores = [x[1] for x in score_dict]\n",
      "    scores = np.array(scores).reshape(len(C_range), len(g_range))\n",
      "\n",
      "    plt.figure(figsize=(8, 6))\n",
      "    plt.subplots_adjust(left=0.05, right=0.95, bottom=0.15, top=0.95)\n",
      "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.spectral)\n",
      "    plt.xlabel('g')\n",
      "    plt.ylabel('C')\n",
      "    plt.colorbar()\n",
      "    plt.xticks(np.arange(len(g_range)), g_range, rotation=45)\n",
      "    plt.yticks(np.arange(len(C_range)), C_range)\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 210
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def laundromat(model, Whole, CV, nspv, max_acc, PCUT):\n",
      "    \n",
      "    # extract data from x. First column is the Y label\n",
      "    D = Whole[Whole[:,0]!=-1]\n",
      "    M = Whole.shape[0]\n",
      "    \n",
      "    X_CV = CV[:,1:]\n",
      "    Y_CV = CV[:,0]\n",
      "    M_CV = len(Y_CV)\n",
      "    \n",
      "    # train\n",
      "    model.fit(D[:,1:], D[:,0])\n",
      "    \n",
      "    # evaluate\n",
      "    p = model.predict(X_CV)\n",
      "    count = 0.0\n",
      "    for i in range(M_CV):\n",
      "        if p[i]==Y_CV[i]:\n",
      "            count+=1\n",
      "    acc = 100*count/M_CV\n",
      "    if acc < max_acc or (acc == max_acc and model.support_vectors_.shape[0]==nspv):\n",
      "        return [Whole, None, max_acc, True, nspv]\n",
      "    \n",
      "    print 'score on CV', acc, 'support vectors', model.support_vectors_.shape[0]\n",
      "    # go deeper\n",
      "    cc = 0\n",
      "    for i in range(M):\n",
      "        Yrec = Whole[i,0]\n",
      "        Xrec = Whole[i,1:]\n",
      "        if Yrec==-1:\n",
      "            prob = model.predict_proba(Xrec)\n",
      "            label = np.argmax(prob)\n",
      "            p = np.max(prob[0,:])\n",
      "            if p > PCUT:\n",
      "                cc += 1\n",
      "                Whole[i,0] = label\n",
      "    \n",
      "    sv_xy = np.hstack([np.atleast_2d(Y[model.support_]).T, model.support_vectors_])\n",
      "        \n",
      "    return [Whole, sv_xy, acc, False, model.support_vectors_.shape[0]]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 313
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "SVM Recursive to inflate new training set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def giveittomebaby(index_tr, index_cv, trials = 10):\n",
      "    fuck_Z = None\n",
      "    fuck_acc = 0.0\n",
      "    fuck_X = None\n",
      "    fuck_Y = None\n",
      "    for times in range(trials):\n",
      "        # read data\n",
      "        x_all = np.array(data.ix[:,:])\n",
      "        y_all = gt_data.astype('int8').copy()\n",
      "        \n",
      "        # reduce to 12 dimmensions\n",
      "        pca = RandomizedPCA(n_components=12, whiten=True)\n",
      "        x_all = pca.fit(x_all).transform(x_all)\n",
      "        \n",
      "        # divide into training and crossvalidation\n",
      "        Whole_Training = np.hstack([y_all[index_tr], x_all[index_tr,:]])\n",
      "        #X_CV, Y_CV = x_all[index_cv,:], y_all[index_cv]\n",
      "        CV = np.hstack([np.atleast_2d(y_all[index_cv]), x_all[index_cv,:]])\n",
      "        \n",
      "        # find the best classifier\n",
      "        clf = svm.SVC(kernel='rbf', cache_size=1000, probability=True, C=10000000., gamma=0.22)\n",
      "        [Z, sv_xy, acc, fu, nnn] = laundromat(clf, Whole_Training, CV, nspv=0., max_acc=0.0, PCUT = 0.95)\n",
      "        \n",
      "        clf = svm.SVC(kernel='rbf', cache_size=1000, probability=True, C=10000000., gamma=0.275)\n",
      "        fu = False\n",
      "        acc = 0.9\n",
      "        PCUT = 0.95\n",
      "        print 'nnn', nnn\n",
      "        while fu == False:\n",
      "            print '+++', Z.shape, CV.shape, nnn, acc, PCUT\n",
      "            [Z, sv_xy, acc, fu, nnn] = laundromat(clf, Z, CV, nnn, acc, PCUT)\n",
      "            print '---', Z.shape, sv_xy.shape, acc, fu, nnn\n",
      "        \n",
      "        print 'accuracy', acc, 'support v', nnn\n",
      "        if acc >= fuck_acc:\n",
      "            fuck_acc = acc\n",
      "            fuck_X = sv_xy[:,1:]\n",
      "            fuck_Y = sv_xy[:,0]\n",
      "    \n",
      "    print '_____________________predicting kahuna 9,000 on model with acc', fuck_acc\n",
      "                     \n",
      "    return [fuck_X, fuck_Y, fuck_acc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 326
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Matrix_runs = 3\n",
      "PP = np.ones((9000, Matrix_runs))*-1\n",
      "scores = np.zeros((11,))\n",
      "SV_X, SV_Y = np.zeros((1,12)), np.array([0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MPP, NPP = PP.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 328
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(NPP):\n",
      "    listo = np.arange(1000)\n",
      "    np.random.shuffle(listo)\n",
      "    crossval, train = np.split(listo, [300])\n",
      "    train = np.concatenate((train, np.arange(1000,10000)))\n",
      "    print train.shape, crossval.shape\n",
      "    \n",
      "    [SV_X, SV_Y, acc] = giveittomebaby(train, crossval, trials=3)\n",
      "    \n",
      "    print 'inserting with acc', acc, 'in column', i\n",
      "    scores[i] = acc\n",
      "    SV_X = np.vstack([SV_X, SVZ[:,1:]])\n",
      "    SV_Y = np.concatenate([SV_Y, SVZ[:,0]])\n",
      "    print '--------------------', SV_X.shape, SV_Y.shape\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(9700,) (300,)\n",
        "(9700, 13)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (300, 13) 0.0 0.0 0.95\n",
        "score on CV"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 94.6666666667 support vectors 451\n",
        "nnn"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 451\n",
        "+++ (9700, 13) (300, 13) 451 0.9 0.95\n",
        "(9700, 13) (300, 13) 451 0.9 0.95\n",
        "score on CV"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 96.3333333333 support vectors 1793\n",
        "---"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (9700, 13) (1793, 13) 96.3333333333 False 1793\n",
        "+++ (9700, 13) (300, 13) 1793 96.3333333333 0.95\n",
        "(9700, 13) (300, 13) 1793 96.3333333333 0.95\n",
        "score on CV"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 96.3333333333 support vectors 2164\n",
        "---"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "need more than 4 values to unpack",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-329-9a298eddd7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0mSV_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSV_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgiveittomebaby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'inserting with acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-326-2eaad157c70d>\u001b[0m in \u001b[0;36mgiveittomebaby\u001b[0;34m(index_tr, index_cv, trials)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mfu\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'+++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCUT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msv_xy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaundromat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'---'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msv_xy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: need more than 4 values to unpack"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (9700, 13) (2164, 13) 96.3333333333 False 2164\n",
        "+++ (9700, 13) (300, 13) 2164 96.3333333333 0.95\n",
        "(9700, 13) (300, 13) 2164 96.3333333333 0.95\n"
       ]
      }
     ],
     "prompt_number": 329
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print SV_X.shape\n",
      "print SV_X[0:10,0:3]\n",
      "\n",
      "print SV_Y.shape\n",
      "print SV_Y[0:10]\n",
      "\n",
      "\n",
      "print SV_X[0,:], SV_Y[0]\n",
      "\n",
      "SV_X = SV_X[1:,:]\n",
      "SV_Y = SV_Y[1:]\n",
      "\n",
      "print SV_X[0,:], SV_Y[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_model = svm.SVC(kernel='rbf', cache_size=1000, probability=False, C=10000000, gamma = 0.277)\n",
      "my_model.fit(SV_X, SV_Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xxx = np.array(data)\n",
      "yyy = gt_data.astype('int8')[0:300]\n",
      "\n",
      "pca = RandomizedPCA(n_components=12, whiten=True)\n",
      "xxx = pca.fit(xxx).transform(xxx[0:300])\n",
      "\n",
      "from sklearn.metrics import *  \n",
      "aaa=my_model.predict(xxx)\n",
      "print(classification_report(yyy, aaa))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "SV_Y[0:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "my_model.support_vectors_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_X = pca.transform(np.array(data))[1000:,:]\n",
      "print final_X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = my_model.predict(final_X)\n",
      "print p.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = np.hstack([np.atleast_2d(np.arange(1,9001)).T, np.atleast_2d(p).T])\n",
      "print pred[0:20,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'To submitt add header: Id,Solution'\n",
      "np.savetxt('./predictions_friday.csv', pred, fmt='%i,%i')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}