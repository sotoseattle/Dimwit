{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%cd '~/Dropbox/fjs6/Journal/ideolog/Dimwit/examples/titanic/data/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/fjs6/Dropbox/fjs6/Journal/ideolog/Dimwit/examples/titanic/data\n"
       ]
      }
     ],
     "prompt_number": 496
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from pandas import *\n",
      "import pandas\n",
      "import math\n",
      "import random\n",
      "from sklearn import preprocessing\n",
      "from sklearn import svm\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 780
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy as sc\n",
      "from scipy.optimize import fmin_l_bfgs_b\n",
      "\n",
      "# MODULE FOR NEURAL NETWORK\n",
      "\n",
      "\n",
      "def groundTruth(y, numLabels):\n",
      "    '''Expanded Y Matrix, I.e. label: 3 => [0,0,0,1,0,0,0,0,0,0]'''\n",
      "    m = y.shape[0]\n",
      "    groundTruth = np.zeros((m, numLabels))\n",
      "    for row in range(m):\n",
      "        groundTruth[row, y[row,0]] = 1\n",
      "    return groundTruth\n",
      "\n",
      "def sigmoid(z):\n",
      "    return np.vectorize(lambda x: 1/(1+np.exp(-x) + 1E-11))(z)\n",
      "\n",
      "def sigmoid_gradient(z):\n",
      "    return (sigmoid(z)*(1-sigmoid(z)))\n",
      "\n",
      "def unroll_thetas(n, layers, thetas_rolled):\n",
      "    thetas = [None]*len(layers)\n",
      "    start_cut = 0\n",
      "    cols = n+1\n",
      "    for i, rows in enumerate(layers):\n",
      "        end_cut = start_cut + cols*rows\n",
      "        thetas[i] = thetas_rolled[start_cut:end_cut].reshape(rows,cols)\n",
      "        start_cut = end_cut\n",
      "        cols = rows+1\n",
      "    return thetas\n",
      "\n",
      "def randomize_thetas(rows,cols):\n",
      "    epsilon_init = 0.12;\n",
      "    return np.random.rand(rows, cols+1) * 2 * epsilon_init - epsilon_init;\n",
      "\n",
      "def grad_by_hand(t, layers, x, y, regul_lambda, number_of_thetitas):\n",
      "    epsilon = 1e-4\n",
      "    n = t.size\n",
      "    grad = np.ones((n,)).astype('float64')\n",
      "    for i in range(number_of_thetitas):\n",
      "        t1 = np.copy(t)\n",
      "        t2 = np.copy(t)\n",
      "        t1[i] += epsilon\n",
      "        t2[i] -= epsilon\n",
      "        ja = j(t1, layers, x, y, regul_lambda)\n",
      "        jb = j(t2, layers, x, y, regul_lambda)\n",
      "        grad[i] = (ja-jb)/(2*epsilon)\n",
      "    return grad\n",
      "\n",
      "def feedforward(theta, input_v):\n",
      "    '''one layer forward computation, asumes input_v has no bias'''\n",
      "    m = input_v.shape[0]\n",
      "    input_v = np.hstack([np.ones((m,1)),input_v])\n",
      "    z = input_v.dot(theta.T)\n",
      "    return sigmoid(z)\n",
      "\n",
      "def h(thetas_rolled, layers, one_x):\n",
      "    thetas = unroll_thetas(len(one_x), layers, thetas_rolled)\n",
      "    a = one_x\n",
      "    for t in thetas:\n",
      "        a = sigmoid(np.hstack([1,a]) .dot(t.T))\n",
      "    return a\n",
      "\n",
      "def j(thetas_rolled, layers, x, y, lam):\n",
      "    m,n = x.shape\n",
      "    thetas = unroll_thetas(n, layers, thetas_rolled)\n",
      "    y_bloat = groundTruth(np.array(y), layers[-1])\n",
      "    a, r = x, 0.\n",
      "    for t in thetas:\n",
      "        a = np.hstack([np.ones((m,1)),a])\n",
      "        a = sigmoid(a.dot(t.T))\n",
      "        r += np.sum(t[:,1:]**2)    \n",
      "    J = (np.sum(-y_bloat*np.log(a) - (1-y_bloat)*np.log(1-a)) + (r*lam)/2)/m\n",
      "    return J\n",
      "\n",
      "def v(thetas_rolled, layers, x, y, lam):\n",
      "    m,n = x.shape\n",
      "    thetas = unroll_thetas(n, layers, thetas_rolled)\n",
      "    num_thetas = len(layers)\n",
      "    y_bloat = groundTruth(np.array(y), layers[-1])\n",
      "    \n",
      "    # forward => fill lists of 'activations' and 'z'\n",
      "    a, z = [x], [None]\n",
      "    for i in range(num_thetas):\n",
      "        a[-1] = np.hstack([np.ones((m,1)),a[-1]])\n",
      "        z.append(a[-1].dot(thetas[i].T))\n",
      "        a.append(sigmoid(z[-1]))\n",
      "    \n",
      "    # backwards => fill list of deltas\n",
      "    d = [(a[-1] - y_bloat)]    \n",
      "    for i in range(num_thetas, 1, -1):\n",
      "        d.insert(0, (d[0].dot(thetas[i-1][:,1:])) * sigmoid_gradient(z[i-1]))\n",
      "    \n",
      "    # forward => compute gradient\n",
      "    V = np.array([])\n",
      "    for i in range(num_thetas):\n",
      "        Vwip = (d[i].T.dot(a[i]) + (lam*thetas[i]))/m\n",
      "        Vwip[:,0] -= (lam/m) * thetas[i][:,0]\n",
      "        V = np.hstack([V, Vwip.flatten()])\n",
      "    return V\n",
      "\n",
      "def optimizeThetas(tinit, layers, x, y, lam, visual=True):\n",
      "    def f(w):\n",
      "        return j(w, layers, x, y, lam)\n",
      "    def fprime(w):\n",
      "        return v(w, layers, x, y, lam)\n",
      "    \n",
      "    [thetas, f, d] = fmin_l_bfgs_b(func=f, x0=tinit, fprime=fprime, maxiter=1000)\n",
      "    if visual:\n",
      "        print thetas[0:10]\n",
      "        print f\n",
      "        print d\n",
      "    return thetas\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 781
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tr_data = read_csv('train.csv')\n",
      "M = tr_data.shape[0]\n",
      "test_data = read_csv('test.csv')\n",
      "data = concat([tr_data, test_data], ignore_index=True)\n",
      "print 'cutout train set:', M"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "cutout train set: 891\n"
       ]
      }
     ],
     "prompt_number": 499
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Sex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 500,
       "text": [
        "0       male\n",
        "1     female\n",
        "2     female\n",
        "3     female\n",
        "4       male\n",
        "5       male\n",
        "6       male\n",
        "7       male\n",
        "8     female\n",
        "9     female\n",
        "10    female\n",
        "11    female\n",
        "12      male\n",
        "13      male\n",
        "14    female\n",
        "...\n",
        "1294      male\n",
        "1295      male\n",
        "1296      male\n",
        "1297      male\n",
        "1298      male\n",
        "1299    female\n",
        "1300    female\n",
        "1301    female\n",
        "1302    female\n",
        "1303    female\n",
        "1304      male\n",
        "1305    female\n",
        "1306      male\n",
        "1307      male\n",
        "1308      male\n",
        "Name: Sex, Length: 1309, dtype: object"
       ]
      }
     ],
     "prompt_number": 500
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "\n",
      "def extract_patt(patt, linea):\n",
      "    matchObj = re.match(patt, linea)\n",
      "    result = NaN\n",
      "    if matchObj:\n",
      "        return matchObj.group(1).lower()\n",
      "    else:\n",
      "        print \"No match!!\"\n",
      "        return NaN\n",
      "\n",
      "def extract_title(linea):\n",
      "    chuchi = extract_patt('^.+,\\s(.+)\\..+', linea)\n",
      "    if chuchi in ['don', 'dr', 'jonkheer']:\n",
      "        chuchi = 'mr'\n",
      "    elif chuchi in ['dona', 'mrs. martin (elizabeth l', 'lady', 'mme', 'ms']:\n",
      "        chuchi = 'mrs'\n",
      "    elif chuchi in ['mme', 'mlle', 'miss']:\n",
      "        chuchi = 'mss'\n",
      "    return chuchi\n",
      "\n",
      "def extract_last_name(linea):\n",
      "    return extract_patt('^(.+),\\s.+\\..+', linea)\n",
      "\n",
      "def extract_first_letter(linea):\n",
      "    return extract_patt('^(.)\\d*', linea)\n",
      "\n",
      "data['Sex'] = data.Sex.map(lambda x: 1. if x=='male' else -1.)\n",
      "data['lastName'] = data.Name.map(extract_last_name)\n",
      "data['title'] = data.Name.map(extract_title)\n",
      "\n",
      "#data['family'] = data.Parch + data.SibSp\n",
      "def get_fam(rec):\n",
      "    n = rec['Parch'] + rec['SibSp']\n",
      "    if n==0:\n",
      "        return -1.\n",
      "    elif n==1:\n",
      "        return 1.\n",
      "    else:\n",
      "        return 2.\n",
      "    return rec\n",
      "data['family'] = data.apply(get_fam, axis=1)\n",
      "\n",
      "# Adding personal power\n",
      "data['charisma'] = data.Age*data.Pclass\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 659
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.Sex"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 502,
       "text": [
        "0     1\n",
        "1    -1\n",
        "2    -1\n",
        "3    -1\n",
        "4     1\n",
        "5     1\n",
        "6     1\n",
        "7     1\n",
        "8    -1\n",
        "9    -1\n",
        "10   -1\n",
        "11   -1\n",
        "12    1\n",
        "13    1\n",
        "14   -1\n",
        "...\n",
        "1294    1\n",
        "1295    1\n",
        "1296    1\n",
        "1297    1\n",
        "1298    1\n",
        "1299   -1\n",
        "1300   -1\n",
        "1301   -1\n",
        "1302   -1\n",
        "1303   -1\n",
        "1304    1\n",
        "1305   -1\n",
        "1306    1\n",
        "1307    1\n",
        "1308    1\n",
        "Name: Sex, Length: 1309, dtype: float64"
       ]
      }
     ],
     "prompt_number": 502
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fare NaN\n",
      "fares_by_class = data.groupby('Pclass').Fare.median()\n",
      "\n",
      "def getFare(example):\n",
      "    if isnull(example['Fare']):\n",
      "        example['Fare'] = fares_by_class[example['Pclass']]\n",
      "    return example\n",
      "\n",
      "data = data.apply(getFare, axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 503
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.title.unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 782,
       "text": [
        "array(['mr', 'mrs', 'mss', 'master', 'rev', 'major', 'sir', 'col', 'capt',\n",
        "       'the countess'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 782
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def numeralize(ristra, label):\n",
      "    things = Series(ristra.unique()).to_dict()\n",
      "    levels = {v:k+1 for k, v in things.items()}\n",
      "    data[label] = ristra.map(lambda x: levels[x] if notnull(levels[x]) else -1)\n",
      "\n",
      "def featurize(ristra, label):\n",
      "    things = Series(ristra.unique()).to_dict()\n",
      "    levels = {v:(label+'_'+str(v)) for k, v in things.items() if notnull(v)}\n",
      "    for k in levels:\n",
      "        data[levels[k]] = ristra.map(lambda x: 1 if x==k else 0)\n",
      "\n",
      "#titulos = Series(data.title.unique())\n",
      "#titulos = Series(data.title.unique()).to_dict()\n",
      "#titulos_levels = {v:k for k, v in titulos.items()}\n",
      "#data['title_level'] = data.title.map(lambda x: titulos_levels[x])\n",
      "\n",
      "numeralize(data.title, 'title_level')\n",
      "numeralize(data.Embarked, 'port_level')\n",
      "featurize(data.Embarked, 'pt')\n",
      "featurize(data.title, 'tt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 504
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 505,
       "text": [
        "Index([u'Age', u'Cabin', u'Embarked', u'Fare', u'Name', u'Parch', u'PassengerId', u'Pclass', u'Sex', u'SibSp', u'Survived', u'Ticket', u'lastName', u'title', u'family', u'charisma', u'title_level', u'port_level', u'pt_Q', u'pt_S', u'pt_C', u'tt_sir', u'tt_the countess', u'tt_capt', u'tt_mss', u'tt_mrs', u'tt_master', u'tt_mr'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 505
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 505
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 505
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "AGE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IMPORTANT TO SET THIS BEFORE WE FILL AGES\n",
      "data['has_Age'] = data.Age.map(lambda x: 0. if isnull(x) else 1.)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 506
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# GET MEDIAN AGE PER TITLE\n",
      "qqq = data.groupby('title')\n",
      "ages_by_title = qqq.Age.median()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 507
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# FILL NaN WITH MEDIAN ACCORDING TO TITLE\n",
      "def getAge(example):\n",
      "    if isnull(example['Age']):\n",
      "        example['charisma'] = ages_by_title[example['title']]*example['Pclass']\n",
      "    else:\n",
      "        example['charisma'] = example['Age']*example['Pclass']\n",
      "    return example\n",
      "\n",
      "data = data.apply(getAge, axis=1)\n",
      "\n",
      "#print 'unextracted titles:', data[data.Age.isnull()==True].shape[0]\n",
      "#print data.ix[0:20,['title', 'Age']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 508
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "int(40/2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 509,
       "text": [
        "20"
       ]
      }
     ],
     "prompt_number": 509
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_relatives(record):\n",
      "    if record['Sex']==-1.:\n",
      "        sol1 = data[(data.Ticket==record['Ticket']) | (data.lastName==record['lastName']) | (data.Cabin==record['Cabin'])][data.PassengerId!=record['PassengerId']][data.Survived==1]\n",
      "        sol2 = sol1[sol1.Age>record['Age']]\n",
      "        if sol2.empty==False:\n",
      "            return 10. #int(max(sol2['Age'])/record['Age'])\n",
      "        elif sol1.empty==False:\n",
      "            return 1.\n",
      "    elif record['Sex']==1.:\n",
      "        sol1 = data[(data.Ticket==record['Ticket']) | (data.lastName==record['lastName']) | (data.Cabin==record['Cabin'])][data.PassengerId!=record['PassengerId']][data.Survived==1][data.Sex==1.]\n",
      "        sol2 = sol1[sol1.Age>record['Age']+20]\n",
      "        if sol2.empty==False:\n",
      "            return 10.\n",
      "        elif sol1.empty==False:\n",
      "            return 1.\n",
      "    else:\n",
      "        return NaN\n",
      "    return -1.\n",
      "\n",
      "data['overseer'] = data.apply(get_relatives, axis=1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 672
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "NEURAL NETWORK ALL_________________________________"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neuracc(thetas, x, y):\n",
      "    tot = y.shape[0]\n",
      "    count = 0.0\n",
      "    for i, truth in enumerate(y):\n",
      "        sol = h(thetas, layers, x[i])\n",
      "        if np.argmax(sol)== truth[0]:\n",
      "            count +=1.\n",
      "    return 100.*count/tot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 650
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "munged = data.copy()\n",
      "munged = munged[['Survived', 'title_level', 'family', 'Fare', 'Pclass', 'overseer']].ix[:,]\n",
      "\n",
      "munged.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 676,
       "text": [
        "Index([u'Survived', u'title_level', u'family', u'Fare', u'Pclass', u'overseer'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 676
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "\n",
      "y_all = munged.pop('Survived')\n",
      "\n",
      "\n",
      "feats = len(munged.columns)\n",
      "print feats, munged.columns\n",
      "\n",
      "total_features = len(munged.columns)\n",
      "\n",
      "lala = 1.\n",
      "\n",
      "YY = np.atleast_2d(y_all[0:M]).T\n",
      "\n",
      "\n",
      "opt_score = 0.\n",
      "opt_lala = 0.\n",
      "\n",
      "x_all = np.array(munged).astype('float64')\n",
      "scaler = preprocessing.StandardScaler().fit(x_all)\n",
      "x_all = scaler.transform(x_all)\n",
      "\n",
      "X0 = x_all[0:M,:]\n",
      "nodes = X0.shape[1]\n",
      "layers = [nodes, nodes, nodes, 2]\n",
      "pufi = randomize_thetas(nodes,nodes).flatten()\n",
      "tinit = np.hstack([pufi, pufi, pufi, randomize_thetas(2,nodes).flatten()])\n",
      "\n",
      "cut = M-200\n",
      "#for lala in [1., 10., 30.]:\n",
      "#for lala in [0.48, 0.52]:\n",
      "for lala in [0.01]:\n",
      "#for lala in [1.]:\n",
      "#for lala in [.5]:\n",
      "    ot = optimizeThetas(tinit, layers, X0[0:cut,:], YY[0:cut,:], lala)\n",
      "    new_acc = neuracc(ot, X0[cut:cut+200,:], YY[cut:cut+200,:])\n",
      "    print 'lala', lala, new_acc\n",
      "    if new_acc > opt_score:\n",
      "        opt_score = new_acc\n",
      "        opt_lala = lala\n",
      "\n",
      "print '_______________BEST SCORE:', opt_score\n",
      "print 'best lambda:', opt_lala"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 Index([u'title_level', u'family', u'Fare', u'Pclass', u'overseer'], dtype=object)\n",
        "[ -7.31326536  -5.44261222   7.34026547   3.51685097  11.21323916\n",
        "  -2.13271961   0.59020693   4.21142072  -0.99295054  -0.51222947]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.731541103708\n",
        "{'warnflag': 1, 'task': 'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT', 'grad': array([ -4.73167570e-03,  -5.55820597e-03,  -6.63132831e-03,\n",
        "        -4.32191797e-05,  -3.59628521e-03,  -1.08469959e-02,\n",
        "         4.87563824e-04,  -5.02730708e-04,  -9.72712439e-06,\n",
        "        -2.88786349e-04,  -1.36224546e-03,   2.43462585e-03,\n",
        "        -4.06713398e-03,  -4.54303322e-03,   1.34219753e-03,\n",
        "         1.77427654e-03,  -1.55535515e-03,   3.46793354e-03,\n",
        "         5.60840362e-05,  -6.37546308e-04,   1.46745601e-04,\n",
        "         4.49153028e-03,  -3.94788011e-04,  -1.62202331e-04,\n",
        "         1.61296150e-03,   1.16039571e-03,  -1.94710428e-03,\n",
        "         7.65795399e-04,  -9.34186126e-04,   1.07611222e-03,\n",
        "         1.50071130e-03,  -4.55224019e-05,   3.50290432e-04,\n",
        "         2.81966591e-04,   2.19327722e-05,  -1.11563960e-04,\n",
        "         6.88900644e-05,   2.55906922e-07,  -2.37570513e-04,\n",
        "         2.09759819e-04,   4.67602730e-04,   1.96577583e-05,\n",
        "         2.34315073e-03,   3.41250453e-04,   1.65406017e-03,\n",
        "         2.62512007e-04,   5.69377111e-05,   8.74552838e-04,\n",
        "        -4.01811537e-03,  -5.43756964e-04,  -3.07312876e-03,\n",
        "        -4.48168938e-04,  -2.20555968e-04,  -1.51063733e-03,\n",
        "        -1.71309247e-03,  -1.24413692e-03,  -3.66543753e-04,\n",
        "        -1.46521483e-03,  -7.18862745e-04,  -1.33431619e-03,\n",
        "        -3.23027713e-04,  -1.08806186e-04,  -3.01621678e-04,\n",
        "        -1.73553596e-04,  -1.14991008e-04,   1.18302734e-04,\n",
        "        -7.29102830e-04,  -7.29026401e-04,  -9.30415495e-04,\n",
        "        -5.46341333e-04,  -3.49239180e-04,  -4.24522263e-04,\n",
        "        -2.78012115e-04,  -8.72295287e-05,  -2.63036009e-04,\n",
        "        -1.48618928e-04,  -9.49386366e-05,   1.17099130e-04,\n",
        "        -2.79588045e-03,  -2.62757460e-03,  -2.39546261e-03,\n",
        "        -5.18772719e-04,  -2.63671009e-03,  -6.74098418e-04,\n",
        "        -2.19465005e-03,  -2.04986863e-03,  -1.68808956e-03,\n",
        "        -4.95461117e-04,  -2.01783738e-03,  -6.52710608e-04,\n",
        "         7.10897664e-04,   5.42115104e-04,   7.86577602e-04,\n",
        "         5.46155088e-04,   4.40464758e-04,   2.55954316e-04,\n",
        "        -9.63510377e-04,  -7.34220873e-04,  -9.92183404e-04,\n",
        "        -7.33125829e-04,  -5.21502884e-04,  -3.07758128e-04]), 'nit': 1001, 'funcalls': 1112}\n",
        "lala"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.01 86.5\n",
        "_______________BEST SCORE: 86.5\n",
        "best lambda: 0.01\n"
       ]
      }
     ],
     "prompt_number": 677
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "I AM HERE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bad_0 = 0.0\n",
      "bad_1 = 0.0\n",
      "for i in range(691, 891):\n",
      "    p = np.argmax(h(ot, layers, x_all[i,:]))\n",
      "    if p != y_all[i]:\n",
      "        if p==0:\n",
      "            bad_0 += 1.\n",
      "        else:\n",
      "            bad_1 += 1.\n",
      "\n",
      "print bad_0\n",
      "print bad_1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "15.0\n",
        "12.0\n"
       ]
      }
     ],
     "prompt_number": 678
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thetas_list = unroll_thetas(nodes, layers, ot)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 679
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thetas_list[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 680,
       "text": [
        "(5, 6)"
       ]
      }
     ],
     "prompt_number": 680
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a1 = feedforward(thetas_list[0], munged)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 681
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a2 = feedforward(thetas_list[1], a1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 682
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a3 = feedforward(thetas_list[2], a2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 683
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a3[0:10,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 684,
       "text": [
        "array([[ 0.99999877,  0.87450318,  0.99999751,  0.38057452,  0.27343332],\n",
        "       [ 0.99999877,  0.87430025,  0.99999751,  0.38024769,  0.27338909],\n",
        "       [ 0.99999869,  0.97993849,  0.99999745,  0.99785229,  0.98023863],\n",
        "       [ 0.99999877,  0.8742685 ,  0.99999751,  0.38015028,  0.27328543],\n",
        "       [ 0.99999959,  0.91597101,  0.99999916,  0.98696181,  0.95974943],\n",
        "       [ 0.99999959,  0.91085358,  0.99999916,  0.98358087,  0.95240991],\n",
        "       [ 0.99999902,  0.87943823,  0.999998  ,  0.58690262,  0.43963648],\n",
        "       [ 0.99999838,  0.91390453,  0.99999676,  0.46526922,  0.31020024],\n",
        "       [ 0.99999874,  0.87934491,  0.99999743,  0.3896873 ,  0.27726382],\n",
        "       [ 0.99999877,  0.87422568,  0.99999751,  0.38001944,  0.27314376]])"
       ]
      }
     ],
     "prompt_number": 684
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 684
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Prepare NN test predictions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this way I train on 891-50\n",
      "opt_lala = 0.01\n",
      "ot = optimizeThetas(ot, layers, X0, YY, opt_lala)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ -9.45484559e+00  -7.90898315e+00   1.00843347e+01   5.00190346e+00\n",
        "   1.49785037e+01  -2.97402163e+00   2.52723799e+00   5.62540469e+00\n",
        "  -7.47484350e-01   3.29786331e-04]\n",
        "0.707527921699\n",
        "{'warnflag': 1, 'task': 'STOP: TOTAL NO. of ITERATIONS EXCEEDS LIMIT', 'grad': array([ -4.30118088e-04,  -1.90319092e-03,  -1.80382143e-03,\n",
        "        -2.65330937e-05,  -3.04485796e-05,  -1.56975803e-03,\n",
        "         6.36055576e-04,  -5.95223838e-04,   3.07220197e-04,\n",
        "         6.95971100e-04,  -1.09115765e-03,   1.61012109e-03,\n",
        "         6.64319122e-04,   8.36616400e-04,  -1.53949427e-04,\n",
        "        -6.43479019e-04,   5.24871339e-04,  -2.38499983e-04,\n",
        "        -2.84374375e-04,   3.08585514e-04,   7.68095228e-04,\n",
        "         8.20106744e-04,  -9.08807457e-04,   1.03989414e-03,\n",
        "         8.92379653e-05,  -9.70137118e-04,   4.31607211e-04,\n",
        "         2.59305425e-04,  -1.13513170e-03,   2.55556713e-03,\n",
        "        -6.50943357e-06,  -9.75327388e-05,   1.15188972e-04,\n",
        "         1.85007955e-04,  -5.70636179e-05,  -6.82152972e-05,\n",
        "        -8.31866885e-05,  -2.46005191e-04,  -4.81989129e-04,\n",
        "         5.10072844e-06,  -3.17970926e-04,  -3.65227681e-04,\n",
        "        -6.40535226e-05,  -1.81718538e-04,  -6.08806471e-05,\n",
        "        -5.02993213e-05,   5.23987320e-06,  -2.85551064e-04,\n",
        "        -5.86281647e-04,  -8.18004503e-05,  -2.63088148e-04,\n",
        "        -1.02190323e-04,  -1.79911084e-04,  -2.10015948e-04,\n",
        "         3.19803673e-04,   4.11684946e-04,   1.77124835e-04,\n",
        "         3.69586218e-04,  -9.93970377e-05,  -3.50246473e-04,\n",
        "        -1.77239561e-04,  -8.75180084e-05,  -9.70555873e-05,\n",
        "         1.83934231e-07,  -8.13007815e-06,   7.58329663e-05,\n",
        "        -1.76171022e-04,  -4.98435909e-05,  -1.12664703e-04,\n",
        "        -2.27042512e-04,  -1.71483686e-04,   2.54923862e-04,\n",
        "        -1.65876787e-04,  -7.47727654e-05,  -7.37849079e-05,\n",
        "        -2.15741691e-05,  -1.35065100e-05,   7.34206398e-05,\n",
        "         8.33068128e-04,   5.80885262e-04,   1.83685675e-04,\n",
        "        -3.13068435e-05,   6.27391387e-04,  -1.02214628e-04,\n",
        "         5.84612319e-04,   5.34608350e-04,  -1.21624517e-04,\n",
        "         7.32228403e-05,   5.45046662e-04,  -4.15312101e-06,\n",
        "        -3.59448203e-04,  -3.15211543e-04,  -2.46289557e-04,\n",
        "        -3.11530844e-04,  -9.06112748e-05,  -5.21295015e-05,\n",
        "         8.93964360e-05,   7.03013675e-05,  -1.41014075e-05,\n",
        "         6.90179981e-05,  -4.43920319e-05,   2.41357392e-06]), 'nit': 1001, 'funcalls': 1113}\n"
       ]
      }
     ],
     "prompt_number": 686
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_test = x_all[M:,:]\n",
      "\n",
      "mm = x_test.shape[0]\n",
      "NN_sol = np.zeros((mm,2))\n",
      "\n",
      "for i, record in enumerate(x_test):\n",
      "    NN_sol[i,0] = np.argmax(h(ot, layers, record))\n",
      "    NN_sol[i,1] = np.max(h(ot, layers, record))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 687
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 687
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 687
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "---STOP HERE----"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_test = x_all[M:,:]\n",
      "\n",
      "mm = x_test.shape[0]\n",
      "sol = np.zeros((mm,2))\n",
      "\n",
      "for i, record in enumerate(x_test):\n",
      "    q1 = i+M+1\n",
      "    q2 = np.argmax(h(ot, layers, record))\n",
      "    s = `q1` + ',' +`int(q2)`\n",
      "    sol[i,0] = q1\n",
      "    sol[i,1] = q2\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 688
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'To submitt add header: PassengerId,Survived'\n",
      "np.savetxt('./predictions_nn_last.csv', sol, fmt='%i,%i')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "To submitt add header: PassengerId,Survived\n"
       ]
      }
     ],
     "prompt_number": 689
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "0.035"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_all = munged.pop('Survived')\n",
      "\n",
      "\n",
      "#a = [('title_level', 'family', 'Fare', 'Pclass', 'overseer', 'port_level')]\n",
      "\n",
      "C_range = 10.**arange(-2, 3)\n",
      "g_range = arange(0.001, 0.25, 0.05)\n",
      "param_grid = dict(gamma=g_range, C=C_range)\n",
      "clf = svm.SVC(kernel='rbf', cache_size=1000)\n",
      "\n",
      "YY = y_all[0:M]\n",
      "\n",
      "x_all = np.array(munged_ACTIVATED)\n",
      "#scaler = preprocessing.StandardScaler().fit(x_all)\n",
      "#x_all = scaler.transform(x_all)\n",
      "\n",
      "X0 = x_all[0:M,:]\n",
      "cv = StratifiedKFold(YY, n_folds=5)\n",
      "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv, verbose=1)\n",
      "\n",
      "print '_______________BEST SCORE:', grid.best_score_\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "DIVIDE THE SETS & RUN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "munged = data.copy().ix[:,]\n",
      "\n",
      "    \n",
      "munged.pop('Cabin')\n",
      "munged.pop('Embarked')\n",
      "munged.pop('Name')\n",
      "munged.pop('PassengerId')\n",
      "#munged.pop('SibSp')\n",
      "#munged.pop('Parch')\n",
      "munged.pop('Ticket')\n",
      "munged.pop('lastName')\n",
      "munged.pop('title')\n",
      "munged.pop('has_Age')\n",
      "munged.pop('Age')\n",
      "#munged.pop('Pclass')\n",
      "#munged.pop('overseer3')\n",
      "#munged.pop('title_level')\n",
      "\n",
      "#munged.pop('Sex')\n",
      "#munged.pop('Fare')\n",
      "#munged.pop('pt_Q')\n",
      "\n",
      "munged.pop('tt_sir')\n",
      "munged.pop('tt_the countess')\n",
      "munged.pop('tt_capt')\n",
      "munged.pop('tt_mss')\n",
      "munged.pop('tt_mrs')\n",
      "munged.pop('tt_master')\n",
      "munged.pop('tt_mr')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "munged.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 715,
       "text": [
        "Index([u'Fare', u'Parch', u'Pclass', u'Sex', u'SibSp', u'Survived', u'family', u'charisma', u'title_level', u'port_level', u'pt_Q', u'pt_S', u'pt_C', u'overseer'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 715
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools\n",
      "\n",
      "y_all = munged.pop('Survived')\n",
      "feats = len(munged.columns)\n",
      "print feats, munged.columns\n",
      "\n",
      "#b = ['Age', 'Sex', 'binAge', 'pt_S', 'pt_C', 'overseer2', 'overseer3']\n",
      "#'tt_sir', 'tt_the countess', 'tt_capt', 'tt_mss', 'tt_mrs', 'tt_master', 'tt_mr', 'tt_miss',\n",
      "# 'has_Age'\n",
      "#a = []\n",
      "#for features in itertools.combinations(b, 1):\n",
      "#    a.append(['title_level', 'family', 'Fare', 'Pclass', 'overseer', 'charisma', 'pt_Q'] + list(features))\n",
      "#a = list(itertools.combinations(munged.columns, 7))\n",
      "\n",
      "a = [('title_level', 'family', 'Fare', 'Pclass', 'overseer')]\n",
      "\n",
      "C_range = 10.**arange(-2, 3)\n",
      "g_range = arange(0.001, 0.25, 0.05)\n",
      "param_grid = dict(gamma=g_range, C=C_range)\n",
      "clf = svm.SVC(kernel='rbf', cache_size=1000)\n",
      "\n",
      "YY = y_all[0:M]\n",
      "\n",
      "opt_score = 0.\n",
      "opt_features = []\n",
      "opt_grid = None\n",
      "for feature_set in a:\n",
      "    x_all = np.array(munged[np.array(feature_set)])\n",
      "    scaler = preprocessing.StandardScaler().fit(x_all)\n",
      "    x_all = scaler.transform(x_all)\n",
      "\n",
      "    X0 = x_all[0:M,:]\n",
      "    cv = StratifiedKFold(YY, n_folds=5)\n",
      "    grid = GridSearchCV(clf, param_grid=param_grid, cv=cv, verbose=1)\n",
      "    grid.fit(X0, YY)\n",
      "    if grid.best_score_ > opt_score:\n",
      "        opt_score = grid.best_score_\n",
      "        opt_features = feature_set\n",
      "        opt_grid = grid\n",
      "\n",
      "print '_______________BEST SCORE:', opt_score\n",
      "print 'features:', opt_features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    1.2s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "13 Index([u'Fare', u'Parch', u'Pclass', u'Sex', u'SibSp', u'family', u'charisma', u'title_level', u'port_level', u'pt_Q', u'pt_S', u'pt_C', u'overseer'], dtype=object)\n",
        "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
        "_______________BEST SCORE:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.838383838384\n",
        "features: ('title_level', 'family', 'Fare', 'Pclass', 'overseer')\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done 125 out of 125 | elapsed:    3.4s finished\n"
       ]
      }
     ],
     "prompt_number": 716
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "munged.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 717,
       "text": [
        "Index([u'Fare', u'Parch', u'Pclass', u'Sex', u'SibSp', u'family', u'charisma', u'title_level', u'port_level', u'pt_Q', u'pt_S', u'pt_C', u'overseer'], dtype=object)"
       ]
      }
     ],
     "prompt_number": 717
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 717
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Narrow down the hyperparms on the opt feature set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Narrow down the hyperparms on the opt feature set\n",
      "x_all = np.array(munged[np.array(opt_features)])\n",
      "scaler = preprocessing.StandardScaler().fit(x_all)\n",
      "x_all = scaler.transform(x_all)\n",
      "\n",
      "C_range = arange(5, 15., 0.5)\n",
      "g_range = arange(0.5, 1.2, 0.1)\n",
      "#C_range = [0.7]\n",
      "#g_range = [0.11]\n",
      "\n",
      "param_grid = dict(gamma=g_range, C=C_range)\n",
      "clf = svm.SVC(kernel='rbf', cache_size=1000)\n",
      "opt_grid = GridSearchCV(clf, param_grid=param_grid, cv=cv, verbose=1)\n",
      "opt_grid.fit(X0, YY)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
        "[Parallel(n_jobs=1)]: Done  50 jobs       | elapsed:    1.3s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done 200 jobs       | elapsed:    5.1s\n",
        "[Parallel(n_jobs=1)]: Done 450 jobs       | elapsed:   11.9s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done 700 out of 700 | elapsed:   19.2s finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 733,
       "text": [
        "GridSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[ 0.  1. ...,  1.  0.], n_folds=5),\n",
        "       estimator=SVC(C=1.0, cache_size=1000, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
        "       param_grid={'C': array([  5. ,   5.5,   6. ,   6.5,   7. ,   7.5,   8. ,   8.5,   9. ,\n",
        "         9.5,  10. ,  10.5,  11. ,  11.5,  12. ,  12.5,  13. ,  13.5,\n",
        "        14. ,  14.5]), 'gamma': array([ 0.5,  0.6,  0.7,  0.8,  0.9,  1. ,  1.1])},\n",
        "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
        "       verbose=1)"
       ]
      }
     ],
     "prompt_number": 733
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"The best classifier is: \", opt_grid.best_estimator_)\n",
      "score_dict = opt_grid.grid_scores_\n",
      "scores = [x[1] for x in score_dict]\n",
      "scores = np.array(scores).reshape(len(C_range), len(g_range))\n",
      "plt.figure(figsize=(8, 6))\n",
      "plt.subplots_adjust(left=0.05, right=0.95, bottom=0.15, top=0.95)\n",
      "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.spectral)\n",
      "plt.xlabel('g')\n",
      "plt.ylabel('C')\n",
      "plt.colorbar()\n",
      "plt.xticks(np.arange(len(g_range)), g_range, rotation=45)\n",
      "plt.yticks(np.arange(len(C_range)), C_range)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('The best classifier is: ', SVC(C=9.5, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.89999999999999991, kernel='rbf', max_iter=-1, probability=False,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False))\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAAGMCAYAAAAY1wRWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJ0TgKMkJEbj/D9Q8YwiUQG3SAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x107cbf910>"
       ]
      }
     ],
     "prompt_number": 734
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opt_grid.best_score_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 735,
       "text": [
        "0.84287317620650959"
       ]
      }
     ],
     "prompt_number": 735
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 735
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 735
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cut = 200\n",
      "X1 = x_all[0:M-cut,:]\n",
      "Y1 = y_all[0:M-cut]\n",
      "\n",
      "clff = svm.SVC(kernel='rbf', C= opt_grid.best_estimator_.C, gamma = opt_grid.best_estimator_.gamma, cache_size=1000, probability=True)\n",
      "clff.fit(X1, Y1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 760,
       "text": [
        "SVC(C=9.5, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.89999999999999991, kernel='rbf', max_iter=-1, probability=True,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 760
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 760
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clff.support_vectors_.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 761,
       "text": [
        "(320, 5)"
       ]
      }
     ],
     "prompt_number": 761
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bad_0 = 0.0\n",
      "bad_1 = 0.0\n",
      "\n",
      "cut = 200\n",
      "X1 = x_all[M-cut:M,:]\n",
      "Y1 = y_all[M-cut:M].values\n",
      "\n",
      "## NN\n",
      "NN = np.zeros((cut,2))\n",
      "\n",
      "for i, record in enumerate(X1):\n",
      "    NN[i,0] = np.argmax(h(ot, layers, record))\n",
      "    NN[i,1] = np.max(h(ot, layers, record))\n",
      "\n",
      "\n",
      "\n",
      "a = clff.predict(X1)\n",
      "b = clff.predict_proba(X1)\n",
      "\n",
      "for i in range(len(Y1)):\n",
      "    svm = int(a[i])\n",
      "    nn = int(NN[i,0])\n",
      "    if svm!=nn:\n",
      "        if b[i, svm]<NN[i,1]:\n",
      "            s = ' nn'\n",
      "            p = nn\n",
      "        else:\n",
      "            s = ' svm'\n",
      "            p = svm\n",
      "    else:\n",
      "        s = ''\n",
      "        p = svm\n",
      "    \n",
      "    if p != Y1[i]:\n",
      "        print 'ERROR' + s\n",
      "        if p==0:\n",
      "            bad_0 += 1.\n",
      "        else:\n",
      "            bad_1 += 1.\n",
      "    else:\n",
      "        if s!='':\n",
      "            print 'ok' + s\n",
      "        \n",
      "\n",
      "\n",
      "print bad_0\n",
      "print bad_1\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ok svm\n",
        "ok nn\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR svm\n",
        "ERROR\n",
        "ERROR\n",
        "ok nn\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR svm\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ERROR\n",
        "ok nn\n",
        "ok nn\n",
        "ok nn\n",
        "ERROR\n",
        "12.0\n",
        "10.0\n"
       ]
      }
     ],
     "prompt_number": 779
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "OUTPUT TEST PREDICTIONS ON ALL TRAINING DATA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#clff = svm.SVC(kernel='rbf', C= opt_grid.best_estimator_.C, gamma = opt_grid.best_estimator_.gamma, cache_size=1000, probability=False)\n",
      "\n",
      "#clf = opt_grid.best_estimator_\n",
      "clf = svm.SVC(kernel='rbf', C= opt_grid.best_estimator_.C, gamma = opt_grid.best_estimator_.gamma, cache_size=1000, probability=True)\n",
      "\n",
      "x_all_train = x_all[0:M]\n",
      "y_all_train = y_all[0:M]\n",
      "x_test = x_all[M:]\n",
      "\n",
      "clf.fit(x_all_train, y_all_train)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 739,
       "text": [
        "SVC(C=9.5, cache_size=1000, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=0.89999999999999991, kernel='rbf', max_iter=-1, probability=True,\n",
        "  random_state=None, shrinking=True, tol=0.001, verbose=False)"
       ]
      }
     ],
     "prompt_number": 739
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = clf.predict(x_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 740
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = clf.predict_proba(x_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 741
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 742,
       "text": [
        "array([ 0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.])"
       ]
      }
     ],
     "prompt_number": 742
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 743,
       "text": [
        "array([[ 0.84755237,  0.15244763],\n",
        "       [ 0.61337553,  0.38662447],\n",
        "       [ 0.84296417,  0.15703583],\n",
        "       [ 0.84398175,  0.15601825],\n",
        "       [ 0.19166496,  0.80833504],\n",
        "       [ 0.84428022,  0.15571978],\n",
        "       [ 0.13577946,  0.86422054],\n",
        "       [ 0.84912825,  0.15087175],\n",
        "       [ 0.18099472,  0.81900528],\n",
        "       [ 0.84294713,  0.15705287],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84315416,  0.15684584],\n",
        "       [ 0.15336637,  0.84663363],\n",
        "       [ 0.84441689,  0.15558311],\n",
        "       [ 0.16849191,  0.83150809],\n",
        "       [ 0.18354536,  0.81645464],\n",
        "       [ 0.84182015,  0.15817985],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.55727423,  0.44272577],\n",
        "       [ 0.18098013,  0.81901987],\n",
        "       [ 0.84315656,  0.15684344],\n",
        "       [ 0.17402461,  0.82597539],\n",
        "       [ 0.27035181,  0.72964819],\n",
        "       [ 0.84291235,  0.15708765],\n",
        "       [ 0.35774357,  0.64225643],\n",
        "       [ 0.84553887,  0.15446113],\n",
        "       [ 0.16836242,  0.83163758],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.84274475,  0.15725525],\n",
        "       [ 0.89167411,  0.10832589],\n",
        "       [ 0.84370332,  0.15629668],\n",
        "       [ 0.82631717,  0.17368283],\n",
        "       [ 0.18528086,  0.81471914],\n",
        "       [ 0.84300794,  0.15699206],\n",
        "       [ 0.10833671,  0.89166329],\n",
        "       [ 0.84298743,  0.15701257],\n",
        "       [ 0.19135711,  0.80864289],\n",
        "       [ 0.20148999,  0.79851001],\n",
        "       [ 0.84440658,  0.15559342],\n",
        "       [ 0.18625154,  0.81374846],\n",
        "       [ 0.84219851,  0.15780149],\n",
        "       [ 0.84307562,  0.15692438],\n",
        "       [ 0.85337321,  0.14662679],\n",
        "       [ 0.18623881,  0.81376119],\n",
        "       [ 0.18452398,  0.81547602],\n",
        "       [ 0.84351114,  0.15648886],\n",
        "       [ 0.84277551,  0.15722449],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.16055072,  0.83944928],\n",
        "       [ 0.18685133,  0.81314867],\n",
        "       [ 0.11258652,  0.88741348],\n",
        "       [ 0.84296687,  0.15703313],\n",
        "       [ 0.06615568,  0.93384432],\n",
        "       [ 0.18620677,  0.81379323],\n",
        "       [ 0.84299634,  0.15700366],\n",
        "       [ 0.85815169,  0.14184831],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84331324,  0.15668676],\n",
        "       [ 0.84410556,  0.15589444],\n",
        "       [ 0.2512669 ,  0.7487331 ],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84291848,  0.15708152],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.13663342,  0.86336658],\n",
        "       [ 0.3094144 ,  0.6905856 ],\n",
        "       [ 0.16653199,  0.83346801],\n",
        "       [ 0.18741033,  0.81258967],\n",
        "       [ 0.84473018,  0.15526982],\n",
        "       [ 0.84285443,  0.15714557],\n",
        "       [ 0.3585384 ,  0.6414616 ],\n",
        "       [ 0.18655131,  0.81344869],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.18934212,  0.81065788],\n",
        "       [ 0.8429328 ,  0.1570672 ],\n",
        "       [ 0.2242814 ,  0.7757186 ],\n",
        "       [ 0.83023736,  0.16976264],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.2094804 ,  0.7905196 ],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.18655131,  0.81344869],\n",
        "       [ 0.78031308,  0.21968692],\n",
        "       [ 0.73433401,  0.26566599],\n",
        "       [ 0.84315416,  0.15684584],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84293492,  0.15706508],\n",
        "       [ 0.84554228,  0.15445772],\n",
        "       [ 0.18860833,  0.81139167],\n",
        "       [ 0.19135711,  0.80864289],\n",
        "       [ 0.18282845,  0.81717155],\n",
        "       [ 0.11455227,  0.88544773],\n",
        "       [ 0.58663817,  0.41336183],\n",
        "       [ 0.84340468,  0.15659532],\n",
        "       [ 0.07197196,  0.92802804],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.84315416,  0.15684584],\n",
        "       [ 0.84341966,  0.15658034],\n",
        "       [ 0.12784107,  0.87215893],\n",
        "       [ 0.84351114,  0.15648886],\n",
        "       [ 0.1882088 ,  0.8117912 ],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.1786753 ,  0.8213247 ],\n",
        "       [ 0.85715977,  0.14284023],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.84340468,  0.15659532],\n",
        "       [ 0.1999176 ,  0.8000824 ],\n",
        "       [ 0.83151154,  0.16848846],\n",
        "       [ 0.84343756,  0.15656244],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.84401043,  0.15598957],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.84296747,  0.15703253],\n",
        "       [ 0.18701453,  0.81298547],\n",
        "       [ 0.18610838,  0.81389162],\n",
        "       [ 0.17928058,  0.82071942],\n",
        "       [ 0.19903177,  0.80096823],\n",
        "       [ 0.84554228,  0.15445772],\n",
        "       [ 0.85277689,  0.14722311],\n",
        "       [ 0.10682199,  0.89317801],\n",
        "       [ 0.84712893,  0.15287107],\n",
        "       [ 0.18622046,  0.81377954],\n",
        "       [ 0.16306961,  0.83693039],\n",
        "       [ 0.84350427,  0.15649573],\n",
        "       [ 0.17427979,  0.82572021],\n",
        "       [ 0.84300418,  0.15699582],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.50539814,  0.49460186],\n",
        "       [ 0.84341966,  0.15658034],\n",
        "       [ 0.18620501,  0.81379499],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.84285763,  0.15714237],\n",
        "       [ 0.84299596,  0.15700404],\n",
        "       [ 0.83200921,  0.16799079],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84346134,  0.15653866],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.19135711,  0.80864289],\n",
        "       [ 0.89783669,  0.10216331],\n",
        "       [ 0.84753153,  0.15246847],\n",
        "       [ 0.18615508,  0.81384492],\n",
        "       [ 0.84479459,  0.15520541],\n",
        "       [ 0.8451342 ,  0.1548658 ],\n",
        "       [ 0.84307562,  0.15692438],\n",
        "       [ 0.88526531,  0.11473469],\n",
        "       [ 0.84855786,  0.15144214],\n",
        "       [ 0.85340814,  0.14659186],\n",
        "       [ 0.84307562,  0.15692438],\n",
        "       [ 0.8169401 ,  0.1830599 ],\n",
        "       [ 0.15670935,  0.84329065],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.84264116,  0.15735884],\n",
        "       [ 0.65206831,  0.34793169],\n",
        "       [ 0.84323832,  0.15676168],\n",
        "       [ 0.22509745,  0.77490255],\n",
        "       [ 0.1882088 ,  0.8117912 ],\n",
        "       [ 0.84307562,  0.15692438],\n",
        "       [ 0.84282803,  0.15717197],\n",
        "       [ 0.18628683,  0.81371317],\n",
        "       [ 0.0793326 ,  0.9206674 ],\n",
        "       [ 0.18607373,  0.81392627],\n",
        "       [ 0.84279845,  0.15720155],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.18588999,  0.81411001],\n",
        "       [ 0.84798363,  0.15201637],\n",
        "       [ 0.90270535,  0.09729465],\n",
        "       [ 0.28572251,  0.71427749],\n",
        "       [ 0.20660992,  0.79339008],\n",
        "       [ 0.84323832,  0.15676168],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.84556501,  0.15443499],\n",
        "       [ 0.84298743,  0.15701257],\n",
        "       [ 0.85601802,  0.14398198],\n",
        "       [ 0.11548955,  0.88451045],\n",
        "       [ 0.18414104,  0.81585896],\n",
        "       [ 0.84267404,  0.15732596],\n",
        "       [ 0.14161437,  0.85838563],\n",
        "       [ 0.11348971,  0.88651029],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.13181688,  0.86818312],\n",
        "       [ 0.18353464,  0.81646536],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.31954605,  0.68045395],\n",
        "       [ 0.84302382,  0.15697618],\n",
        "       [ 0.14365171,  0.85634829],\n",
        "       [ 0.78253276,  0.21746724],\n",
        "       [ 0.84295056,  0.15704944],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.85715977,  0.14284023],\n",
        "       [ 0.84315416,  0.15684584],\n",
        "       [ 0.77456428,  0.22543572],\n",
        "       [ 0.8429113 ,  0.1570887 ],\n",
        "       [ 0.15314432,  0.84685568],\n",
        "       [ 0.84346134,  0.15653866],\n",
        "       [ 0.19513628,  0.80486372],\n",
        "       [ 0.18746441,  0.81253559],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.18413254,  0.81586746],\n",
        "       [ 0.22493236,  0.77506764],\n",
        "       [ 0.77378173,  0.22621827],\n",
        "       [ 0.68405787,  0.31594213],\n",
        "       [ 0.07340992,  0.92659008],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.8431934 ,  0.1568066 ],\n",
        "       [ 0.13685719,  0.86314281],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.18662336,  0.81337664],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.83151154,  0.16848846],\n",
        "       [ 0.84284036,  0.15715964],\n",
        "       [ 0.84295288,  0.15704712],\n",
        "       [ 0.18622046,  0.81377954],\n",
        "       [ 0.20486278,  0.79513722],\n",
        "       [ 0.84476454,  0.15523546],\n",
        "       [ 0.18860833,  0.81139167],\n",
        "       [ 0.03999868,  0.96000132],\n",
        "       [ 0.31150746,  0.68849254],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.15340158,  0.84659842],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.18622877,  0.81377123],\n",
        "       [ 0.84341966,  0.15658034],\n",
        "       [ 0.28683163,  0.71316837],\n",
        "       [ 0.18749373,  0.81250627],\n",
        "       [ 0.84754683,  0.15245317],\n",
        "       [ 0.18655131,  0.81344869],\n",
        "       [ 0.84385542,  0.15614458],\n",
        "       [ 0.8290715 ,  0.1709285 ],\n",
        "       [ 0.39727688,  0.60272312],\n",
        "       [ 0.18686604,  0.81313396],\n",
        "       [ 0.84255484,  0.15744516],\n",
        "       [ 0.84347901,  0.15652099],\n",
        "       [ 0.84150404,  0.15849596],\n",
        "       [ 0.84346134,  0.15653866],\n",
        "       [ 0.84153269,  0.15846731],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.18618231,  0.81381769],\n",
        "       [ 0.1394041 ,  0.8605959 ],\n",
        "       [ 0.28572251,  0.71427749],\n",
        "       [ 0.13418973,  0.86581027],\n",
        "       [ 0.17187282,  0.82812718],\n",
        "       [ 0.84348486,  0.15651514],\n",
        "       [ 0.83295362,  0.16704638],\n",
        "       [ 0.84274212,  0.15725788],\n",
        "       [ 0.16653199,  0.83346801],\n",
        "       [ 0.85533262,  0.14466738],\n",
        "       [ 0.18622046,  0.81377954],\n",
        "       [ 0.58441765,  0.41558235],\n",
        "       [ 0.07813132,  0.92186868],\n",
        "       [ 0.84351114,  0.15648886],\n",
        "       [ 0.64604356,  0.35395644],\n",
        "       [ 0.84432767,  0.15567233],\n",
        "       [ 0.84440658,  0.15559342],\n",
        "       [ 0.84323832,  0.15676168],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.18609932,  0.81390068],\n",
        "       [ 0.84340468,  0.15659532],\n",
        "       [ 0.84462538,  0.15537462],\n",
        "       [ 0.84755644,  0.15244356],\n",
        "       [ 0.13242737,  0.86757263],\n",
        "       [ 0.84370025,  0.15629975],\n",
        "       [ 0.84291123,  0.15708877],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.84294936,  0.15705064],\n",
        "       [ 0.85329746,  0.14670254],\n",
        "       [ 0.19135711,  0.80864289],\n",
        "       [ 0.84398175,  0.15601825],\n",
        "       [ 0.84712893,  0.15287107],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.23400367,  0.76599633],\n",
        "       [ 0.50937155,  0.49062845],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.15551571,  0.84448429],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.84370332,  0.15629668],\n",
        "       [ 0.84515768,  0.15484232],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.20148999,  0.79851001],\n",
        "       [ 0.76882876,  0.23117124],\n",
        "       [ 0.13685719,  0.86314281],\n",
        "       [ 0.07728696,  0.92271304],\n",
        "       [ 0.84332703,  0.15667297],\n",
        "       [ 0.84300418,  0.15699582],\n",
        "       [ 0.84300418,  0.15699582],\n",
        "       [ 0.84425716,  0.15574284],\n",
        "       [ 0.84298743,  0.15701257],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.84386961,  0.15613039],\n",
        "       [ 0.18793467,  0.81206533],\n",
        "       [ 0.84298743,  0.15701257],\n",
        "       [ 0.8508189 ,  0.1491811 ],\n",
        "       [ 0.84440658,  0.15559342],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.12501375,  0.87498625],\n",
        "       [ 0.89167411,  0.10832589],\n",
        "       [ 0.8458875 ,  0.1541125 ],\n",
        "       [ 0.84346134,  0.15653866],\n",
        "       [ 0.84340468,  0.15659532],\n",
        "       [ 0.84686929,  0.15313071],\n",
        "       [ 0.84294445,  0.15705555],\n",
        "       [ 0.84398175,  0.15601825],\n",
        "       [ 0.18655131,  0.81344869],\n",
        "       [ 0.2068477 ,  0.7931523 ],\n",
        "       [ 0.04607819,  0.95392181],\n",
        "       [ 0.1483226 ,  0.8516774 ],\n",
        "       [ 0.86362546,  0.13637454],\n",
        "       [ 0.58580381,  0.41419619],\n",
        "       [ 0.84398175,  0.15601825],\n",
        "       [ 0.84298404,  0.15701596],\n",
        "       [ 0.8432572 ,  0.1567428 ],\n",
        "       [ 0.13685719,  0.86314281],\n",
        "       [ 0.2719637 ,  0.7280363 ],\n",
        "       [ 0.18628683,  0.81371317],\n",
        "       [ 0.84512189,  0.15487811],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.84755644,  0.15244356],\n",
        "       [ 0.82631717,  0.17368283],\n",
        "       [ 0.84754332,  0.15245668],\n",
        "       [ 0.84298743,  0.15701257],\n",
        "       [ 0.84307257,  0.15692743],\n",
        "       [ 0.84307562,  0.15692438],\n",
        "       [ 0.17913364,  0.82086636],\n",
        "       [ 0.84284036,  0.15715964],\n",
        "       [ 0.11647521,  0.88352479],\n",
        "       [ 0.60711638,  0.39288362],\n",
        "       [ 0.84370332,  0.15629668],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.13926302,  0.86073698],\n",
        "       [ 0.84277551,  0.15722449],\n",
        "       [ 0.8531841 ,  0.1468159 ],\n",
        "       [ 0.36944424,  0.63055576],\n",
        "       [ 0.84349069,  0.15650931],\n",
        "       [ 0.18546022,  0.81453978],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.85700092,  0.14299908],\n",
        "       [ 0.84747539,  0.15252461],\n",
        "       [ 0.28869592,  0.71130408],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.84326036,  0.15673964],\n",
        "       [ 0.84308754,  0.15691246],\n",
        "       [ 0.30150136,  0.69849864],\n",
        "       [ 0.77456428,  0.22543572],\n",
        "       [ 0.18497236,  0.81502764],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.18099472,  0.81900528],\n",
        "       [ 0.84291848,  0.15708152],\n",
        "       [ 0.16277794,  0.83722206],\n",
        "       [ 0.15505598,  0.84494402],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.84295288,  0.15704712],\n",
        "       [ 0.87970979,  0.12029021],\n",
        "       [ 0.24352621,  0.75647379],\n",
        "       [ 0.84315416,  0.15684584],\n",
        "       [ 0.13997794,  0.86002206],\n",
        "       [ 0.84347901,  0.15652099],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.58002651,  0.41997349],\n",
        "       [ 0.84304091,  0.15695909],\n",
        "       [ 0.139513  ,  0.860487  ],\n",
        "       [ 0.16653199,  0.83346801],\n",
        "       [ 0.84398175,  0.15601825],\n",
        "       [ 0.17611122,  0.82388878],\n",
        "       [ 0.8194629 ,  0.1805371 ],\n",
        "       [ 0.84554199,  0.15445801],\n",
        "       [ 0.76918658,  0.23081342],\n",
        "       [ 0.17138107,  0.82861893],\n",
        "       [ 0.84292553,  0.15707447],\n",
        "       [ 0.84300901,  0.15699099],\n",
        "       [ 0.18620221,  0.81379779],\n",
        "       [ 0.84294936,  0.15705064],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.11293464,  0.88706536],\n",
        "       [ 0.2512669 ,  0.7487331 ],\n",
        "       [ 0.84322506,  0.15677494],\n",
        "       [ 0.84291924,  0.15708076],\n",
        "       [ 0.84777275,  0.15222725],\n",
        "       [ 0.65206831,  0.34793169],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.84347901,  0.15652099],\n",
        "       [ 0.21047879,  0.78952121],\n",
        "       [ 0.57782634,  0.42217366],\n",
        "       [ 0.84291179,  0.15708821],\n",
        "       [ 0.18619806,  0.81380194],\n",
        "       [ 0.84340468,  0.15659532],\n",
        "       [ 0.84291258,  0.15708742],\n",
        "       [ 0.84338659,  0.15661341],\n",
        "       [ 0.81973421,  0.18026579],\n",
        "       [ 0.31895679,  0.68104321],\n",
        "       [ 0.22450821,  0.77549179],\n",
        "       [ 0.17826535,  0.82173465],\n",
        "       [ 0.84294016,  0.15705984],\n",
        "       [ 0.83749085,  0.16250915],\n",
        "       [ 0.1152667 ,  0.8847333 ],\n",
        "       [ 0.84300418,  0.15699582],\n",
        "       [ 0.09681787,  0.90318213],\n",
        "       [ 0.84340468,  0.15659532],\n",
        "       [ 0.84337445,  0.15662555],\n",
        "       [ 0.18635299,  0.81364701],\n",
        "       [ 0.84515768,  0.15484232],\n",
        "       [ 0.1693182 ,  0.8306818 ],\n",
        "       [ 0.8465422 ,  0.1534578 ],\n",
        "       [ 0.17838032,  0.82161968],\n",
        "       [ 0.84292563,  0.15707437],\n",
        "       [ 0.84240822,  0.15759178],\n",
        "       [ 0.84296641,  0.15703359],\n",
        "       [ 0.18608907,  0.81391093],\n",
        "       [ 0.84374094,  0.15625906],\n",
        "       [ 0.18655131,  0.81344869],\n",
        "       [ 0.12316268,  0.87683732],\n",
        "       [ 0.18694784,  0.81305216],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.22020256,  0.77979744],\n",
        "       [ 0.84300418,  0.15699582],\n",
        "       [ 0.84359711,  0.15640289],\n",
        "       [ 0.22241126,  0.77758874]])"
       ]
      }
     ],
     "prompt_number": 743
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = []\n",
      "for i in range(len(x_test)):\n",
      "    svm = int(a[i])\n",
      "    nn = int(NN_sol[i,0])\n",
      "    if svm==nn:\n",
      "        c.append(svm)\n",
      "    else:\n",
      "        print 892+i, b[i, svm], NN_sol[i,1]\n",
      "        if b[i, svm]>=NN_sol[i,1]:\n",
      "            c.append(svm)\n",
      "        else:\n",
      "            print '---nn'\n",
      "            c.append(nn)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "910 0.55727422586 0.65452110343\n",
        "---nn\n",
        "929 0.798510011442 0.583671797854\n",
        "972 0.780313083288 0.928944405867\n",
        "---nn\n",
        "982 0.586638169279 0.501992013202\n",
        "1017 0.494601857749 0.999582828835\n",
        "---nn\n",
        "1046 0.652068309519 0.920646421272\n",
        "---nn\n",
        "1061 0.793390078331 0.649670169974\n",
        "1084 0.77456428016 0.921758381897\n",
        "---nn\n",
        "1093 0.773781726266 0.921325443817\n",
        "---nn\n",
        "1109 0.960001324024 0.914990243708\n",
        "1122 0.60272311557 0.976186290487\n",
        "---nn\n",
        "1141 0.58441765027 0.504765231053\n",
        "1165 0.490628445736 0.999560157577\n",
        "---nn\n",
        "1172 0.798510011442 0.583671797854\n",
        "1173 0.768828759461 0.92123221964\n",
        "---nn\n",
        "1198 0.953921807112 0.795222877789\n",
        "1201 0.585803809252 0.503031097746\n",
        "1219 0.607116381041 0.559439366029\n",
        "1236 0.77456428016 0.921758381897\n",
        "---nn\n",
        "1251 0.580026511271 0.510329581069\n",
        "1271 0.652068309519 0.920646421272\n",
        "---nn\n",
        "1275 0.577826341298 0.513162496032\n",
        "1282 0.681043206895 0.598155581178\n"
       ]
      }
     ],
     "prompt_number": 744
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "m = a.shape[0]\n",
      "aa = range(892,892+m)\n",
      "y_test = np.vstack([aa, a]).T\n",
      "print 'To submitt add header: PassengerId,Survived'\n",
      "print y_test[0:10,:]\n",
      "np.savetxt('./predictions_svm_nn.csv', y_test, fmt='%i,%i')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "To submitt add header: PassengerId,Survived\n",
        "[[ 892.    0.]\n",
        " [ 893.    0.]\n",
        " [ 894.    0.]\n",
        " [ 895.    0.]\n",
        " [ 896.    1.]\n",
        " [ 897.    0.]\n",
        " [ 898.    1.]\n",
        " [ 899.    0.]\n",
        " [ 900.    1.]\n",
        " [ 901.    0.]]\n"
       ]
      }
     ],
     "prompt_number": 745
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}